{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mikalainis/AI-Agent-Capstone/blob/main/Trader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:33:46.135726Z",
          "iopub.execute_input": "2025-11-13T21:33:46.136045Z",
          "iopub.status.idle": "2025-11-13T21:33:46.143045Z",
          "shell.execute_reply.started": "2025-11-13T21:33:46.136013Z",
          "shell.execute_reply": "2025-11-13T21:33:46.141924Z"
        },
        "id": "ruyonHmVI_pu"
      },
      "outputs": [],
      "execution_count": 11
    },
    {
      "cell_type": "markdown",
      "source": [
        "## âš™ï¸ Section 1: Setup\n"
      ],
      "metadata": {
        "id": "c7PBcOEjI_px"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2: Import components\n",
        "\n",
        "Now, import the specific components you'll need for this notebook. This keeps your code organized and ensures we have access to the necessary building blocks."
      ],
      "metadata": {
        "id": "VzkT_3qxI_py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install --upgrade --quiet \\\n",
        "     \"google-adk==1.18.0\" \\\n",
        "     \"google-cloud-aiplatform[evaluation]>=1.100.0\" \\\n",
        "     \"rouge-score>=0.1.2\" \\\n",
        "     \"tabulate>=0.9.0\"\\\n",
        "    #  \"google-genai\"\\\n",
        "    #  \"alpaca-trade-api\"\\\n",
        "    #  \"duckduckgo-search\"\\\n",
        "    #  \"python-dotenv\"\\\n",
        "    #  \"pydantic\"\n",
        "%pip install -q google-adk[a2a]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cN3xkBb7pgtE",
        "outputId": "c8134508-3cc7-432c-ac9e-48a87bb6cb76"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.1/278.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m56.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m788.2/788.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m141.5/141.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "import vertexai\n",
        "from vertexai import agent_engines\n",
        "from IPython.display import JSON, display\n",
        "\n",
        "import json\n",
        "import requests\n",
        "import subprocess\n",
        "import uuid\n",
        "\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.agents.remote_a2a_agent import (\n",
        "    RemoteA2aAgent,\n",
        "    AGENT_CARD_WELL_KNOWN_PATH,\n",
        ")\n",
        "\n",
        "from google.adk.a2a.utils.agent_to_a2a import to_a2a\n",
        "from google.adk.models.google_llm import Gemini\n",
        "from google.adk.runners import Runner\n",
        "from google.genai import types\n",
        "\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.memory import InMemoryMemoryService\n",
        "from google.adk.tools import load_memory, preload_memory\n",
        "\n",
        "print(\"âœ… ADK components imported successfully.\")\n",
        "\n",
        "# Hide additional warnings in the notebook\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "print(\"âœ… Imports completed successfully\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:33:46.145438Z",
          "iopub.execute_input": "2025-11-13T21:33:46.145732Z",
          "iopub.status.idle": "2025-11-13T21:34:30.80119Z",
          "shell.execute_reply.started": "2025-11-13T21:33:46.145709Z",
          "shell.execute_reply": "2025-11-13T21:34:30.799583Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zf_gDY38I_py",
        "outputId": "763a1b52-b154-474c-dd49-9bfe8e5aa960"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ADK components imported successfully.\n",
            "âœ… Imports completed successfully\n"
          ]
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3: Add Cloud Credentials to Secrets\n",
        "\n",
        "1. In the top menu bar of the notebook editor, select `Add-ons` then `Google Cloud SDK`.\n",
        "2. Click on `Link Account`\n",
        "3. Select your Google Cloud Account\n",
        "4. Attach to the notebook\n",
        "   \n",
        "This cell retrieves your Google Cloud credentials from Kaggle Secrets and configures them for use. These credentials allow the notebook to authenticate with Google Cloud services like Vertex AI Agent Engine."
      ],
      "metadata": {
        "id": "d11paLVRI_py"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "from google.colab import auth\n",
        "\n",
        "\n",
        "# Retrieve keys from Colab Secrets\n",
        "try:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n",
        "    os.environ[\"ALPACA_KEY\"] = userdata.get('alpaca_api_key')\n",
        "    os.environ[\"ALPACA_SECRET\"] = userdata.get('alpaca_secret')\n",
        "    print(\"âœ… API Keys loaded from Colab Secrets\")\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error loading keys: {e}\")\n",
        "    print(\"Make sure you added the keys in the ðŸ”‘ Secrets tab on the left!\")\n",
        "\n",
        "# Authenticate the user (opens a pop-up to log in)\n",
        "import sys\n",
        "\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "\n",
        "    auth.authenticate_user()\n",
        "\n",
        "print(\"âœ… Cloud credentials configured\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:30.802351Z",
          "iopub.execute_input": "2025-11-13T21:34:30.803106Z",
          "iopub.status.idle": "2025-11-13T21:34:30.976716Z",
          "shell.execute_reply.started": "2025-11-13T21:34:30.803076Z",
          "shell.execute_reply": "2025-11-13T21:34:30.975649Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8K35YOcI_pz",
        "outputId": "64a8dffd-3018-40c5-9486-996d0b1e33c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… API Keys loaded from Colab Secrets\n",
            "âœ… Cloud credentials configured\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.4: Set your PROJECT_ID\n",
        "\n",
        "**Important:** Make sure to replace `\"your-project-id\"` with your actual Google Cloud project ID. You can find your project ID in the [Google Cloud Console](https://console.cloud.google.com/)."
      ],
      "metadata": {
        "id": "LFCCQ5pEI_pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Set your PROJECT_ID\n",
        "PROJECT_ID = \"gen-lang-client-0275412497\"  # TODO: Replace with your project ID https://aistudio.google.com/app/api-keys\n",
        "# \"myfirstapp-e165d\"\n",
        "os.environ[\"GOOGLE_CLOUD_PROJECT\"] = PROJECT_ID\n",
        "\n",
        "if PROJECT_ID == \"your-project-id\" or not PROJECT_ID:\n",
        "    raise ValueError(\"âš ï¸ Please replace 'your-project-id' with your actual Google Cloud Project ID.\")\n",
        "\n",
        "print(f\"âœ… Project ID set to: {PROJECT_ID}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:39:02.29647Z",
          "iopub.execute_input": "2025-11-13T21:39:02.296792Z",
          "iopub.status.idle": "2025-11-13T21:39:02.302855Z",
          "shell.execute_reply.started": "2025-11-13T21:39:02.296772Z",
          "shell.execute_reply": "2025-11-13T21:39:02.301659Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi_AxJSLI_pz",
        "outputId": "2adc96c8-3125-4cb1-d586-f7211b0131de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Project ID set to: gen-lang-client-0275412497\n"
          ]
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.5: Enable Google Cloud APIs\n",
        "\n",
        "For this tutorial, you'll need to enable the following APIs in the Google Cloud Console.\n",
        "\n",
        "- Vertex AI API\n",
        "- Cloud Storage API\n",
        "- Cloud Logging API\n",
        "- Cloud Monitoring API\n",
        "- Cloud Trace API\n",
        "- Telemetry API\n",
        "\n",
        "You can [use this link to open the Google Cloud Console](https://console.cloud.google.com/flows/enableapi?apiid=aiplatform.googleapis.com,storage.googleapis.com,logging.googleapis.com,monitoring.googleapis.com,cloudtrace.googleapis.com,telemetry.googleapis.com) and follow the steps there to enable these APIs."
      ],
      "metadata": {
        "id": "PSHwI-zkI_pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸ—ï¸ Section 2: Create Your Agent with ADK\n",
        "\n",
        "Before we deploy, we need a functional agent to host. We'll build a **Weather Assistant** designed to serve as our sample agent.\n",
        "\n",
        "This agent is optimized for production testing with the following configuration:\n",
        "\n",
        "- **Model:** Uses gemini-2.5-flash-lite for low latency and cost-efficiency.\n",
        "- **Tools:** Includes a `get_weather` function to demonstrate tool execution.\n",
        "- **Persona:** Responds conversationally to prove the instruction-following capabilities.\n",
        "\n",
        "This demonstrates the foundational ADK architecture we are about to package: **Agent + Tools + Instructions**.\n",
        "\n",
        "We'll create the following files and directory structure:\n",
        "\n",
        "```\n",
        "sample_agent/\n",
        "â”œâ”€â”€ agent.py                  # The logic\n",
        "â”œâ”€â”€ requirements.txt          # The libraries\n",
        "â”œâ”€â”€ .env                      # The secrets/config\n",
        "â””â”€â”€ .agent_engine_config.json # The hardware specs\n",
        "```"
      ],
      "metadata": {
        "id": "iI9kqaggI_pz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1: Create agent directory\n",
        "\n",
        "We need a clean workspace to package our agent for deployment. We will create a directory named `sample_agent`.\n",
        "\n",
        "All necessary files - including the agent code, dependencies, and configurationâ€”will be written into this folder to prepare it for the `adk deploy` command."
      ],
      "metadata": {
        "id": "oDnYV1yWI_pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Create simple agent - all code for the agent will live in this directory\n",
        "!mkdir -p sample_agent\n",
        "\n",
        "print(f\"âœ… Sample Agent directory created\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:30.985515Z",
          "iopub.execute_input": "2025-11-13T21:34:30.985771Z",
          "iopub.status.idle": "2025-11-13T21:34:31.1364Z",
          "shell.execute_reply.started": "2025-11-13T21:34:30.985723Z",
          "shell.execute_reply": "2025-11-13T21:34:31.135026Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s97fHMdcI_p0",
        "outputId": "fc0b7e74-cd0c-4bc8-ead2-a6bb8e7e4712"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sample Agent directory created\n"
          ]
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2: Create requirements file\n",
        "\n",
        "The Agent Engine builds a dedicated environment for your agent. To ensure it runs correctly, we must declare our dependencies.\n",
        "\n",
        "We will write a `requirements.txt` file containing the Python packages needed for the agent."
      ],
      "metadata": {
        "id": "KipfNWyEI_p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample_agent/requirements.txt\n",
        "\n",
        "google-adk\n",
        "opentelemetry-instrumentation-google-genai"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:31.139468Z",
          "iopub.execute_input": "2025-11-13T21:34:31.139797Z",
          "iopub.status.idle": "2025-11-13T21:34:31.147811Z",
          "shell.execute_reply.started": "2025-11-13T21:34:31.139765Z",
          "shell.execute_reply": "2025-11-13T21:34:31.146539Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "td13QNvYI_p0",
        "outputId": "d365b054-ff7c-4160-d0b4-2bb715197687"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sample_agent/requirements.txt\n"
          ]
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3: Create environment configuration\n",
        "\n",
        "We need to provide the agent with the necessary cloud configuration settings.\n",
        "\n",
        "We will write a `.env` file that sets the cloud location to `global` and explicitly enables the Vertex AI backend for the ADK SDK."
      ],
      "metadata": {
        "id": "qMSk-E8xI_p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample_agent/.env\n",
        "\n",
        "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/locations#global-endpoint\n",
        "GOOGLE_CLOUD_LOCATION=\"global\"\n",
        "\n",
        "# Set to 1 to use Vertex AI, or 0 to use Google AI Studio\n",
        "GOOGLE_GENAI_USE_VERTEXAI=1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:31.148584Z",
          "iopub.execute_input": "2025-11-13T21:34:31.148857Z",
          "iopub.status.idle": "2025-11-13T21:34:31.171757Z",
          "shell.execute_reply.started": "2025-11-13T21:34:31.148836Z",
          "shell.execute_reply": "2025-11-13T21:34:31.170056Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cLWHXr_I_p0",
        "outputId": "695e1d9c-25a3-420f-96cf-de9b3f41c34e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sample_agent/.env\n"
          ]
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration explained:**\n",
        "\n",
        "- `GOOGLE_CLOUD_LOCATION=\"global\"` - Uses the `global` endpoint for Gemini API calls\n",
        "- `GOOGLE_GENAI_USE_VERTEXAI=1` - Configures ADK to use Vertex AI instead of Google AI Studio"
      ],
      "metadata": {
        "id": "XdYxTIU4I_p0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4: Create agent code\n",
        "\n",
        "We will now generate the `agent.py` file. This script defines the behavior of our **Weather Assistant**.\n",
        "\n",
        "Agent Configuration:\n",
        "\n",
        "- ðŸ§  Model: Uses `gemini-2.5-flash-lite` for low latency and cost-efficiency.\n",
        "- ðŸ› ï¸ Tools: Accesses a `get_weather` function to retrieve data.\n",
        "- ðŸ“ Instructions: Follows a system prompt to identify cities and respond in a friendly tone."
      ],
      "metadata": {
        "id": "i8KZV9cUI_p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample_agent/agent.py\n",
        "from google.adk.agents import Agent\n",
        "import vertexai\n",
        "import os\n",
        "from google.adk.agents import LlmAgent\n",
        "from google.adk.models.google_llm import Gemini\n",
        "from google.adk.runners import Runner\n",
        "from google.adk.sessions import InMemorySessionService\n",
        "from google.adk.memory import InMemoryMemoryService\n",
        "from google.adk.tools import load_memory, preload_memory\n",
        "from google.genai import types\n",
        "\n",
        "print(\"âœ… ADK components imported successfully.\")\n",
        "\n",
        "vertexai.init(\n",
        "    project=os.environ[\"GOOGLE_CLOUD_PROJECT\"],\n",
        "    location=os.environ[\"GOOGLE_CLOUD_LOCATION\"],\n",
        ")\n",
        "\n",
        "def get_weather(city: str) -> dict:\n",
        "    \"\"\"\n",
        "    Returns weather information for a given city.\n",
        "\n",
        "    This is a TOOL that the agent can call when users ask about weather.\n",
        "    In production, this would call a real weather API (e.g., OpenWeatherMap).\n",
        "    For this demo, we use mock data.\n",
        "\n",
        "    Args:\n",
        "        city: Name of the city (e.g., \"Tokyo\", \"New York\")\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary with status and weather report or error message\n",
        "    \"\"\"\n",
        "    # Mock weather database with structured responses\n",
        "    weather_data = {\n",
        "        \"san francisco\": {\"status\": \"success\", \"report\": \"The weather in San Francisco is sunny with a temperature of 72Â°F (22Â°C).\"},\n",
        "        \"new york\": {\"status\": \"success\", \"report\": \"The weather in New York is cloudy with a temperature of 65Â°F (18Â°C).\"},\n",
        "        \"london\": {\"status\": \"success\", \"report\": \"The weather in London is rainy with a temperature of 58Â°F (14Â°C).\"},\n",
        "        \"tokyo\": {\"status\": \"success\", \"report\": \"The weather in Tokyo is clear with a temperature of 70Â°F (21Â°C).\"},\n",
        "        \"paris\": {\"status\": \"success\", \"report\": \"The weather in Paris is partly cloudy with a temperature of 68Â°F (20Â°C).\"}\n",
        "    }\n",
        "\n",
        "    city_lower = city.lower()\n",
        "    if city_lower in weather_data:\n",
        "        return weather_data[city_lower]\n",
        "    else:\n",
        "        available_cities = \", \".join([c.title() for c in weather_data.keys()])\n",
        "        return {\n",
        "            \"status\": \"error\",\n",
        "            \"error_message\": f\"Weather information for '{city}' is not available. Try: {available_cities}\"\n",
        "        }\n",
        "\n",
        "# retry_config = types.HttpRetryOptions(\n",
        "#     attempts=5,  # Maximum retry attempts\n",
        "#     exp_base=7,  # Delay multiplier\n",
        "#     initial_delay=1,\n",
        "#     http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
        "# )\n",
        "\n",
        "# print(\"âœ… Agent and Runner created with memory support!\")\n",
        "\n",
        "# async def auto_save_to_memory(callback_context):\n",
        "#     \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
        "#     await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
        "#         callback_context._invocation_context.session\n",
        "#     )\n",
        "\n",
        "root_agent = Agent(\n",
        "    name=\"weather_assistant\",\n",
        "    model=(\"gemini-2.5-flash-lite\"),  # Fast, cost-effective Gemini model\n",
        "    description=\"A helpful weather assistant that provides weather information for cities.\",\n",
        "    instruction=\"\"\"\n",
        "    You are a friendly weather assistant. When users ask about the weather:\n",
        "\n",
        "    1. Identify the city name from their question\n",
        "    2. Use the get_weather tool to fetch current weather information\n",
        "    3. Respond in a friendly, conversational tone\n",
        "    4. If the city isn't available, suggest one of the available cities\n",
        "\n",
        "    Be helpful and concise in your responses.\n",
        "    \"\"\",\n",
        "    tools=[get_weather],\n",
        "    # after_agent_callback=auto_save_to_memory,  # Saves after each turn!\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:31.172879Z",
          "iopub.execute_input": "2025-11-13T21:34:31.173227Z",
          "iopub.status.idle": "2025-11-13T21:34:31.193238Z",
          "shell.execute_reply.started": "2025-11-13T21:34:31.173194Z",
          "shell.execute_reply": "2025-11-13T21:34:31.191853Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kmYdIxjI_p1",
        "outputId": "87eeb7b1-5f5d-4e69-c193-9e2c446ff0c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sample_agent/agent.py\n"
          ]
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## â˜ï¸ Section 3: Deploy to Agent Engine\n",
        "\n",
        "ADK supports multiple deployment platforms. Learn more in the [ADK deployment documentation](https://google.github.io/adk-docs/deploy/).\n",
        "\n",
        "You'll be deploying to [Vertex AI Agent Engine](https://docs.cloud.google.com/agent-builder/agent-engine/overview) in this notebook.\n",
        "\n",
        "### ðŸ”· Vertex AI Agent Engine\n",
        "\n",
        "- **Fully managed** service specifically for AI agents\n",
        "- **Auto-scaling** with session management built-in\n",
        "- **Easy deployment** using [Agent Starter Pack](https://github.com/GoogleCloudPlatform/agent-starter-pack)\n",
        "- ðŸ“š [Deploy to Agent Engine Guide](https://google.github.io/adk-docs/deploy/agent-engine/)\n",
        "\n",
        "**Note**: To help you get started with the runtime, Agent Engine offers a monthly free tier, which you can learn more about in the [documentation](https://docs.cloud.google.com/agent-builder/agent-engine/overview#pricing). The agent deployed in this notebook should stay within the free tier if cleaned up promptly. Note that you can incur costs if the agent is left running.\n",
        "\n",
        "### ðŸš¢ Other Deployment Options\n",
        "\n",
        "### ðŸ”· Cloud Run\n",
        "\n",
        "- Serverless, easiest to start\n",
        "- Perfect for demos and small-to-medium workloads\n",
        "- ðŸ“š [Deploy to Cloud Run Guide](https://google.github.io/adk-docs/deploy/cloud-run/)\n",
        "\n",
        "### ðŸ”· Google Kubernetes Engine (GKE)\n",
        "\n",
        "- Full control over containerized deployments\n",
        "- Best for complex multi-agent systems\n",
        "- ðŸ“š [Deploy to GKE Guide](https://google.github.io/adk-docs/deploy/gke/)"
      ],
      "metadata": {
        "id": "JIwcXNE_I_p1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1: Create deployment configuration\n",
        "\n",
        "The `.agent_engine_config.json` file controls the deployment settings."
      ],
      "metadata": {
        "id": "BP93QmlbI_p1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sample_agent/.agent_engine_config.json\n",
        "{\n",
        "    \"min_instances\": 0,\n",
        "    \"max_instances\": 1,\n",
        "    \"resource_limits\": {\"cpu\": \"1\", \"memory\": \"1Gi\"}\n",
        "}"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:31.194206Z",
          "iopub.execute_input": "2025-11-13T21:34:31.194529Z",
          "iopub.status.idle": "2025-11-13T21:34:31.218987Z",
          "shell.execute_reply.started": "2025-11-13T21:34:31.194504Z",
          "shell.execute_reply": "2025-11-13T21:34:31.21765Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LaHjrFY9I_p1",
        "outputId": "aa4bc379-4c9d-467d-bec5-3f3f3c349c45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing sample_agent/.agent_engine_config.json\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Configuration explained:**\n",
        "\n",
        "- `\"min_instances\": 0` - Scales down to zero when not in use (saves costs)\n",
        "- `\"max_instances\": 1` - Maximum of 1 instance running (sufficient for this demo)\n",
        "- `\"cpu\": \"1\"` - 1 CPU core per instance\n",
        "- `\"memory\": \"1Gi\"` - 1 GB of memory per instance\n",
        "\n",
        "These settings keep costs minimal while providing adequate resources for our weather agent."
      ],
      "metadata": {
        "id": "roxtbAGUI_p2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2: Select deployment region\n",
        "\n",
        "Agent Engine is available in specific regions. We'll randomly select one for this demo."
      ],
      "metadata": {
        "id": "hUj7wSAKI_p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regions_list = [\"europe-west1\", \"europe-west4\", \"us-east4\", \"us-west1\"]\n",
        "deployed_region = random.choice(regions_list)\n",
        "\n",
        "print(f\"âœ… Selected deployment region: {deployed_region}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:31.220181Z",
          "iopub.execute_input": "2025-11-13T21:34:31.220521Z",
          "iopub.status.idle": "2025-11-13T21:34:31.243332Z",
          "shell.execute_reply.started": "2025-11-13T21:34:31.220468Z",
          "shell.execute_reply": "2025-11-13T21:34:31.242014Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsWVekHpI_p2",
        "outputId": "c114ba99-5068-495e-a6fd-1b89435ded01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Selected deployment region: europe-west4\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "markdown",
      "source": [
        "**About regions:**\n",
        "\n",
        "Agent Engine is available in multiple regions. For production:\n",
        "\n",
        "- Choose a region close to your users for lower latency\n",
        "- Consider data residency requirements\n",
        "- Check the [Agent Engine locations documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview#locations)"
      ],
      "metadata": {
        "id": "YIqcdPEbI_p2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3: Deploy the agent\n",
        "\n",
        "This uses the ADK CLI to deploy your agent to Agent Engine."
      ],
      "metadata": {
        "id": "zOuolUcJI_p2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!adk deploy agent_engine --project=$PROJECT_ID --region=$deployed_region sample_agent --agent_engine_config_file=sample_agent/.agent_engine_config.json"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:34:31.244157Z",
          "iopub.execute_input": "2025-11-13T21:34:31.244395Z",
          "iopub.status.idle": "2025-11-13T21:37:36.468795Z",
          "shell.execute_reply.started": "2025-11-13T21:34:31.244377Z",
          "shell.execute_reply": "2025-11-13T21:37:36.467104Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShOyK4fsI_p2",
        "outputId": "af13fae0-d72f-411a-afc1-fb74f09146e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Staging all files in: /content/sample_agent_tmp20251129_003458\n",
            "Copying agent source code...\n",
            "Copying agent source code complete.\n",
            "Resolving files and dependencies...\n",
            "Reading agent engine config from sample_agent/.agent_engine_config.json\n",
            "Reading environment variables from /content/sample_agent/.env\n",
            "\u001b[33mIgnoring GOOGLE_CLOUD_LOCATION in .env as `--region` was explicitly passed and takes precedence\u001b[0m\n",
            "Initializing Vertex AI...\n",
            "Vertex AI initialized.\n",
            "Created sample_agent_tmp20251129_003458/agent_engine_app.py\n",
            "Files and dependencies resolved\n",
            "Deploying to agent engine...\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What just happened:**\n",
        "\n",
        "The `adk deploy agent_engine` command:\n",
        "\n",
        "1. Packages your agent code (`sample_agent/` directory)\n",
        "2. Uploads it to Agent Engine\n",
        "3. Creates a containerized deployment\n",
        "4. Outputs a resource name like: `projects/PROJECT_NUMBER/locations/REGION/reasoningEngines/ID`\n",
        "\n",
        "**Note:** Deployment typically takes 2-5 minutes."
      ],
      "metadata": {
        "id": "ektinDeXI_p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸ¤– Section 4: Retrieve and Test Your Deployed Agent"
      ],
      "metadata": {
        "id": "Viapu-3FI_p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1: Retrieve the deployed agent\n",
        "\n",
        "After deploying with the CLI, we need to retrieve the agent object to interact with it."
      ],
      "metadata": {
        "id": "7K5oDWgCI_p3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize Vertex AI\n",
        "vertexai.init(project=PROJECT_ID, location=deployed_region)\n",
        "\n",
        "# Get the most recently deployed agent\n",
        "agents_list = list(agent_engines.list())\n",
        "if agents_list:\n",
        "    remote_agent = agents_list[0]  # Get the first (most recent) agent\n",
        "    client = agent_engines\n",
        "    print(f\"âœ… Connected to deployed agent: {remote_agent.resource_name}\")\n",
        "else:\n",
        "    print(\"âŒ No agents found. Please deploy first.\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:37:36.470508Z",
          "iopub.execute_input": "2025-11-13T21:37:36.470852Z",
          "iopub.status.idle": "2025-11-13T21:37:37.045605Z",
          "shell.execute_reply.started": "2025-11-13T21:37:36.470816Z",
          "shell.execute_reply": "2025-11-13T21:37:37.044477Z"
        },
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4RRfm9KI_p3",
        "outputId": "5df74026-a15f-4e0a-b206-d84fced39949"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Connected to deployed agent: projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088\n"
          ]
        }
      ],
      "execution_count": 12
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happened:**\n",
        "\n",
        "This cell retrieves your deployed agent:\n",
        "\n",
        "1. Initializes the Vertex AI SDK with your project and region\n",
        "2. Lists all deployed agents in that region\n",
        "3. Gets the first one (most recently deployed)\n",
        "4. Stores it as `remote_agent` for testing"
      ],
      "metadata": {
        "id": "22LYw6ATI_p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2: Test the deployed agent\n",
        "\n",
        "Now let's send a query to your deployed agent!"
      ],
      "metadata": {
        "id": "MHLRWCYII_qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define constants used throughout the notebook\n",
        "APP_NAME = \"MemoryDemoApp\"\n",
        "USER_ID = \"demo_user\"\n",
        "\n",
        "memory_service = (\n",
        "    InMemoryMemoryService()\n",
        ")  # ADK's built-in Memory Service for development and testing\n",
        "\n",
        "# Create Session Service\n",
        "session_service = InMemorySessionService()  # Handles conversations\n",
        "\n",
        "\n",
        "# Create runner with BOTH services\n",
        "runner = Runner(\n",
        "    agent=root_agent,\n",
        "    app_name=\"MemoryDemoApp\",\n",
        "    session_service=session_service,\n",
        "    memory_service=memory_service,  # Memory service is now available!\n",
        ")\n",
        "\n",
        "# User tells agent about their favorite color\n",
        "await run_session(\n",
        "    runner,\n",
        "    \"My favorite color is blue-green. Can you write a Haiku about it?\",\n",
        "    \"conversation-01\",  # Session ID\n",
        ")"
      ],
      "metadata": {
        "id": "MYtrpeK4ylsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async for item in remote_agent.async_stream_query(\n",
        "    message=\"What is the weather in Paris?\",\n",
        "    user_id=\"user_42\",\n",
        "):\n",
        "# This renders an interactive viewer\n",
        "  display(JSON(item))\n",
        "# print(item)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:37:37.046943Z",
          "iopub.execute_input": "2025-11-13T21:37:37.047231Z",
          "iopub.status.idle": "2025-11-13T21:37:41.472923Z",
          "shell.execute_reply.started": "2025-11-13T21:37:37.047202Z",
          "shell.execute_reply": "2025-11-13T21:37:41.472044Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        },
        "collapsed": true,
        "id": "m2ZQQZAiI_qD",
        "outputId": "4dbb180a-764e-467e-8d5e-40aa69a451ed"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "PermissionDenied",
          "evalue": "403 The reasoning engine resource [projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088] is not active.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mprefetch_first\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallable_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_prefetch_first_result_\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m             return _StreamingResponseIterator(\n\u001b[0m\u001b[1;32m    170\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefetch_first_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprefetch_first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, wrapped, prefetch_first_result)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mprefetch_first_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stored_first_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    961\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_MultiThreadedRendezvous\u001b[0m: <_MultiThreadedRendezvous of RPC that terminated with:\n\tstatus = StatusCode.PERMISSION_DENIED\n\tdetails = \"The reasoning engine resource [projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088] is not active.\"\n\tdebug_error_string = \"UNKNOWN:Error received from peer ipv4:192.178.129.95:443 {grpc_message:\"The reasoning engine resource [projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088] is not active.\", grpc_status:7}\"\n>",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mPermissionDenied\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4142504815.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m async for item in remote_agent.async_stream_query(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"What is the weather in Paris?\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0muser_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"user_42\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m ):\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# This renders an interactive viewer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/vertexai/agent_engines/_agent_engines.py\u001b[0m in \u001b[0;36m_method\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   1644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1645\u001b[0m     \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAsyncIterable\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1646\u001b[0;31m         response = self.execution_api_client.stream_query_reasoning_engine(\n\u001b[0m\u001b[1;32m   1647\u001b[0m             request=aip_types.StreamQueryReasoningEngineRequest(\n\u001b[1;32m   1648\u001b[0m                 \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/cloud/aiplatform_v1/services/reasoning_engine_execution_service/client.py\u001b[0m in \u001b[0;36mstream_query_reasoning_engine\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m   1007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1009\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m   1010\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    171\u001b[0m             )\n\u001b[1;32m    172\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mPermissionDenied\u001b[0m: 403 The reasoning engine resource [projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088] is not active."
          ]
        }
      ],
      "execution_count": 15
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happened:**\n",
        "\n",
        "This cell tests your deployed agent:\n",
        "\n",
        "1. Sends the query \"What is the weather in Tokyo?\"\n",
        "2. Streams the response from the agent\n",
        "\n",
        "**Understanding the output:**\n",
        "\n",
        "You'll see multiple items printed:\n",
        "\n",
        "1. **Function call** - Agent decides to call `get_weather` tool\n",
        "2. **Function response** - Result from the tool (weather data)\n",
        "3. **Final response** - Agent's natural language answer"
      ],
      "metadata": {
        "id": "0rdHb0ZkI_qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸ§  Section 5: Long-Term Memory with Vertex AI Memory Bank\n",
        "\n",
        "### What Problem Does Memory Bank Solve?\n",
        "\n",
        "Your deployed agent has **session memory** - it remembers the conversation while you're chatting. But once the session ends, it forgets everything. Each new conversation starts from scratch.\n",
        "\n",
        "**The problem:**\n",
        "\n",
        "- User tells agent \"I prefer Celsius\" today\n",
        "- Tomorrow, user asks about weather â†’ Agent gives Fahrenheit (forgot preference)\n",
        "- User has to repeat preferences every time\n",
        "\n",
        "### ðŸ’¡ What is Vertex AI Memory Bank?\n",
        "\n",
        "Memory Bank gives your agent **long-term memory across sessions**:\n",
        "\n",
        "| Session Memory | Memory Bank |\n",
        "|---------------|-------------|\n",
        "| Single conversation | All conversations |\n",
        "| Forgets when session ends | Remembers permanently |\n",
        "| \"What did I just say?\" | \"What's my favorite city?\" |\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "1. **During conversations** - Agent uses memory tools to search past facts\n",
        "2. **After conversations** - Agent Engine extracts key information (\"User prefers Celsius\")\n",
        "3. **Next session** - Agent automatically recalls and uses that information\n",
        "\n",
        "**Example:**\n",
        "\n",
        "- **Session 1:** User: \"I prefer Celsius\"\n",
        "- **Session 2 (days later):** User: \"Weather in Tokyo?\" â†’ Agent responds in Celsius automatically âœ¨\n",
        "\n",
        "### ðŸ”§ Memory Bank & Your Deployment\n",
        "\n",
        "Your Agent Engine deployment **provides the infrastructure** for Memory Bank, but it's not enabled by default.\n",
        "\n",
        "**To use Memory Bank:**\n",
        "\n",
        "1. Add memory tools to your agent code (`PreloadMemoryTool`)\n",
        "2. Add a callback to save conversations to Memory Bank\n",
        "3. Redeploy your agent\n",
        "\n",
        "Once configured, Memory Bank works automatically - no additional infrastructure needed!\n",
        "\n",
        "### ðŸ“š Learn More\n",
        "\n",
        "- **[ADK Memory Guide](https://google.github.io/adk-docs/sessions/memory/)** - Complete guide with code examples\n",
        "- **[Memory Tools](https://google.github.io/adk-docs/tools/built-in-tools/)** - PreloadMemory and LoadMemory documentation\n",
        "- **[Get started with Memory Bank on ADK](https://github.com/GoogleCloudPlatform/generative-ai/blob/main/agents/agent_engine/memory_bank/get_started_with_memory_bank_on_adk.ipynb)** - Sample notebook that demonstrates how to build ADK agents with memory"
      ],
      "metadata": {
        "id": "RnxYagQRI_qD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## ðŸ§¹ Section 6: Cleanup\n",
        "\n",
        "**âš ï¸ IMPORTANT: Prevent unexpected charges: Always delete resources when done testing!**\n",
        "\n",
        "**Cost Reminders**\n",
        "\n",
        "As a reminder, leaving the agent running can incur costs. Agent Engine offers a monthly free tier, which you can learn more about in the [documentation](https://docs.cloud.google.com/agent-builder/agent-engine/overview#pricing).\n",
        "\n",
        "**Always delete resources when done testing!**\n",
        "\n",
        "When you're done testing and querying your deployed agent, it's recommended to delete your remote agent to avoid incurring additional costs:"
      ],
      "metadata": {
        "id": "rDDJcNyXI_qD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_engines.delete(resource_name=remote_agent.resource_name, force=True)\n",
        "\n",
        "print(\"âœ… Agent successfully deleted\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-11-13T21:37:41.474198Z",
          "iopub.execute_input": "2025-11-13T21:37:41.474513Z",
          "iopub.status.idle": "2025-11-13T21:37:41.634969Z",
          "shell.execute_reply.started": "2025-11-13T21:37:41.474491Z",
          "shell.execute_reply": "2025-11-13T21:37:41.634056Z"
        },
        "id": "4ENAngcYI_qD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea37f876-e392-4955-b445-2e2a2e88de37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:vertexai.agent_engines:Deleting AgentEngine resource: projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088\n",
            "INFO:vertexai.agent_engines:Delete AgentEngine backing LRO: projects/659570041447/locations/europe-west4/operations/8310964989972185088\n",
            "INFO:vertexai.agent_engines:AgentEngine resource deleted: projects/659570041447/locations/europe-west4/reasoningEngines/4065870854213337088\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Agent successfully deleted\n"
          ]
        }
      ],
      "execution_count": 14
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What happened:**\n",
        "\n",
        "This cell deletes your deployed agent:\n",
        "\n",
        "- `resource_name=remote_agent.resource_name` - Identifies which agent to delete\n",
        "- `force=True` - Forces deletion even if the agent is running\n",
        "\n",
        "The deletion process typically takes 1-2 minutes. You can verify deletion in the [Agent Engine Console](https://console.cloud.google.com/vertex-ai/agents/agent-engines)."
      ],
      "metadata": {
        "id": "h5E565a0I_qE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## âœ… Congratulations! You're Ready for Production Deployment\n",
        "\n",
        "You've successfully learned how to deploy ADK agents to Vertex AI Agent Engine - taking your agents from development to production!\n",
        "\n",
        "You now know how to deploy agents with enterprise-grade infrastructure, manage costs, and test production deployments.\n",
        "\n",
        "### ðŸ“š Learn More\n",
        "\n",
        "Refer to the following documentation to learn more:\n",
        "\n",
        "- [ADK Documentation](https://google.github.io/adk-docs/)\n",
        "- [Agent Engine Documentation](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)\n",
        "- [ADK Deployment Guide](https://google.github.io/adk-docs/deploy/agent-engine/)\n",
        "\n",
        "**Other Deployment Options:**\n",
        "\n",
        "- [Cloud Run Deployment](https://google.github.io/adk-docs/deploy/cloud-run/)\n",
        "- [GKE Deployment](https://google.github.io/adk-docs/deploy/gke/)\n",
        "\n",
        "**Production Best Practices:**\n",
        "\n",
        "- Delete test deployments when finished to avoid costs\n",
        "- Enable tracing (`enable_tracing=True`) for debugging\n",
        "- Monitor via [Vertex AI Console](https://console.cloud.google.com/vertex-ai/agents/agent-engines)\n",
        "- Follow [security best practices](https://google.github.io/adk-docs/safety/)"
      ],
      "metadata": {
        "id": "4qs51RMHI_qE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Salck Integration"
      ],
      "metadata": {
        "id": "Fe7UyMdIunZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from slack_sdk import WebClient\n",
        "\n",
        "# Init Client\n",
        "slack_token = os.environ[\"SLACK_BOT_TOKEN\"]\n",
        "client = WebClient(token=slack_token)\n",
        "\n",
        "def request_human_approval(self, decision, reason):\n",
        "    \"\"\"\n",
        "    Sends a message to Slack and pauses for manual confirmation.\n",
        "    \"\"\"\n",
        "    print(f\"ðŸ›‘ HUMAN LOOP: Requesting approval via Slack...\")\n",
        "\n",
        "    # 1. Send Message\n",
        "    message = f\"ðŸš¨ *TRADE ALERT* ðŸš¨\\n\\n*Ticker:* {self.ticker}\\n*Action:* {decision}\\n*Confidence:* {self.state['confidence_score']}%\\n*Reason:* {reason}\\n\\n_Type 'YES' in the terminal to proceed, or anything else to cancel._\"\n",
        "\n",
        "    try:\n",
        "        client.chat_postMessage(channel=\"#trade-alerts\", text=message)\n",
        "\n",
        "        # 2. For the Capstone demo, use Python's input() to simulate the wait\n",
        "        # In a production app, this would be an async webhook listener.\n",
        "        user_response = input(\"Check Slack! Authorize trade? (Type 'YES'): \")\n",
        "\n",
        "        if user_response.strip().upper() == \"YES\":\n",
        "            return True\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"âŒ Slack Error: {e}\")\n",
        "        return False"
      ],
      "metadata": {
        "id": "S1qCc9-1urT0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}